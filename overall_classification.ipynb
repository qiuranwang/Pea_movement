{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6248be-1112-4054-9b0c-8dddf8db0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.linear_model        import LogisticRegression\n",
    "from sklearn.svm        import SVC\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold,ShuffleSplit,StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5d5972-52e2-4a8a-960d-7ff44314381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(string):\n",
    "\n",
    "    data = {}\n",
    "    plant_parts =  np.sort(glob.glob(string))\n",
    "\n",
    "    print(\"n. files: {:}\".format(len(plant_parts)))\n",
    "\n",
    "    for single_plant_parts in plant_parts:\n",
    "\n",
    "        folder,data_type,body_part,stimulus,experiment = single_plant_parts.split('/')\n",
    "\n",
    "        plant,stimulus,bodypart      = experiment[:-4].split('_')\n",
    "\n",
    "        \n",
    "        if plant not in data.keys():\n",
    "            data[plant] = {'wrist':None,'tendril':[],'stimulus':stimulus,'plant':plant}\n",
    "\n",
    "        print('\\r\\r\\r',plant,stimulus,bodypart,end='')\n",
    "\n",
    "        \n",
    "        if 'wrist' in bodypart :\n",
    "\n",
    "            df = pd.read_csv(single_plant_parts)\n",
    "            data[plant]['wrist'] = df\n",
    "\n",
    "        \n",
    "        elif 'tendril' in bodypart :\n",
    "            df = pd.read_csv(single_plant_parts)\n",
    "            data[plant]['tendril'].append(df)\n",
    "\n",
    "        else:\n",
    "            print('bodypart error')\n",
    "\n",
    "    # for each plant\n",
    "    for plant in data.keys():\n",
    "        \n",
    "        \n",
    "        tendril_x = pd.concat(data[plant]['tendril'],axis=1)['col_x']\n",
    "        tendril_y = pd.concat(data[plant]['tendril'],axis=1)['col_y']\n",
    "        tendril_z = pd.concat(data[plant]['tendril'],axis=1)['col_z']\n",
    "\n",
    "        \n",
    "        if type(data[plant]['wrist']) != type(None):\n",
    "\n",
    "            # preprocesses the data\n",
    "            data[plant]['all_bodyparts'] = {\n",
    "                'time_idx':data[plant]['wrist'].index,\n",
    "                'relative_time_idx':data[plant]['wrist'].index/data[plant]['wrist'].index.max(),\n",
    "                'wrist_x':data[plant]['wrist']['col_x']-data[plant]['wrist']['col_x'][0],\n",
    "                'wrist_y':data[plant]['wrist']['col_y']-data[plant]['wrist']['col_y'][0],\n",
    "                'wrist_z':data[plant]['wrist']['col_z']-data[plant]['wrist']['col_z'][0],\n",
    "                'tendril_mean_x' : tendril_x.mean(axis=1)-data[plant]['wrist']['col_x'],\n",
    "                'tendril_mean_y' : tendril_y.mean(axis=1)-data[plant]['wrist']['col_y'],\n",
    "                'tendril_mean_z' : tendril_z.mean(axis=1)-data[plant]['wrist']['col_z'],\n",
    "                'tendril_std_x' : tendril_x.std(axis=1),\n",
    "                'tendril_std_y' : tendril_y.std(axis=1),\n",
    "                'tendril_std_z' : tendril_z.std(axis=1),\n",
    "                'stimulus' : data[plant]['stimulus'],\n",
    "                'plant_num' : data[plant]['plant']\n",
    "            }\n",
    "\n",
    "    \n",
    "    df = pd.DataFrame([])\n",
    "    for plant in data.keys():\n",
    "        if type(data[plant]['wrist']) != type(None) :\n",
    "\n",
    "            aux = pd.DataFrame(data[plant]['all_bodyparts'])\n",
    "\n",
    "            aux['wrist'] = (aux[['wrist_x','wrist_y','wrist_z']]**2).sum(axis=1)**1/2\n",
    "\n",
    "            aux['tendril'] = (aux[['tendril_mean_x','tendril_mean_y','tendril_mean_z']]**2).sum(axis=1)**1/2\n",
    "\n",
    "            aux['d_wrist_x'] = aux['wrist_x'].diff()\n",
    "            aux['d_wrist_y'] = aux['wrist_y'].diff()\n",
    "            aux['d_wrist_z'] = aux['wrist_z'].diff()\n",
    "\n",
    "            aux['d_tendril_mean_x'] = aux['tendril_mean_x'].diff()\n",
    "            aux['d_tendril_mean_y'] = aux['tendril_mean_y'].diff()\n",
    "            aux['d_tendril_mean_z'] = aux['tendril_mean_z'].diff()\n",
    "\n",
    "            aux['d_tendril_std_x'] = aux['tendril_std_x'].diff()\n",
    "            aux['d_tendril_std_y'] = aux['tendril_std_y'].diff()\n",
    "            aux['d_tendril_std_z'] = aux['tendril_std_z'].diff()\n",
    "\n",
    "            df = df.append(aux)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aebb42e-f923-49a5-b62b-d8b38b098461",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'Plant_dataset/coordinates/**/**/*.csv'\n",
    "df     = make_dataset(string)\n",
    "df['time_window'] = df['time_idx'].round(-2)\n",
    "df['relative_time_window']  = df['relative_time_idx'].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9a39d9-71c6-4fd0-86f4-c20ed5d7bd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['time_idx','plant_num','stimulus']].groupby(['plant_num','stimulus']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f05085-008f-4f19-8208-9720da9af0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cut    = 1505\n",
    "time_cut_df = df[df['time_idx']<time_cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c9676-621d-4a7c-9aea-354ca71cf1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = pd.concat([time_cut_df.groupby(['plant_num','stimulus']).mean(),time_cut_df.groupby(['plant_num','stimulus']).std()],axis=1,keys=['mean','std']).reset_index(level=[0,1])\n",
    "extracted_features.columns = ['_'.join(col) for col in extracted_features.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe0fbf-ac80-4175-bd28-048f442b4315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse(extracted_features,features,model):#,get_feature_importance=False):\n",
    "\n",
    "    X_not_norm = extracted_features[features]\n",
    "    y          = extracted_features[('stimulus_')].values\n",
    "\n",
    "    scaler          = StandardScaler().fit(X_not_norm)\n",
    "    X               = scaler.transform(X_not_norm)\n",
    "\n",
    "    rs = StratifiedShuffleSplit(n_splits=25, test_size=.25, random_state=0)\n",
    "\n",
    "    acc                 = []\n",
    "    feature_importances = []\n",
    "    i = 0\n",
    "    for train_index, test_index in rs.split(X,y):\n",
    "        print('\\r',i,' ',end='')\n",
    "        i+=1\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        #if get_feature_importance :\n",
    "\n",
    "        X_val, y_val = X_test,y_test\n",
    "        r = permutation_importance(model, X_val, y_val,\n",
    "                                    n_repeats=30,\n",
    "                                    random_state=0)\n",
    "        \n",
    "        #feature_importances.append(model.feature_importances_)\n",
    "        feature_importances.append(r['importances_mean'])\n",
    "\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        acc.append(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "    return acc,feature_importances\n",
    "\n",
    "def plot_acc(accRF,accLR,accSVC):\n",
    "    \n",
    "    acc = [accRF,accLR,accSVC]\n",
    "    fig,axs = plt.subplots(1,1,figsize=[5,5])\n",
    "    axs.boxplot(acc)\n",
    "    axs.set_xticks([1, 2, 3], ['RF', 'LR', 'SVC'])\n",
    "    axs.grid(True)\n",
    "    axs.set_ylabel('acc')\n",
    "    axs.set_ylim([0,1.1])\n",
    "\n",
    "    #fig,axs = plt.subplots(1,2,figsize=[10,5])\n",
    "    #axs[1].bar(features,np.array(feature_importances).mean(axis=0))\n",
    "    #_=plt.xticks(rotation=90)\n",
    "    #axs[1].set_title(window)\n",
    "    #plt.show()\n",
    "\n",
    "def plot_fi(featRF,featLR,featSVC,features):\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    dfRF  = pd.DataFrame({'features':np.repeat(features,25),'feature importance':np.array(featRF).flatten()})\n",
    "    dfRF['model'] = 'RF'\n",
    "\n",
    "    dfLR  = pd.DataFrame({'features':np.repeat(features,25),'feature importance':np.array(featLR).flatten()})\n",
    "    dfLR['model'] = 'LR'\n",
    "\n",
    "    dfSVC = pd.DataFrame({'features':np.repeat(features,25),'feature importance':np.array(featSVC).flatten()})\n",
    "    dfSVC['model'] = 'SVC'\n",
    "\n",
    "    df = pd.concat([dfRF,dfLR,dfSVC])\n",
    "\n",
    "    sns.boxplot(data=df,y='feature importance',hue='features',x='model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e80bdc-187c-4d2a-8293-84d71456953a",
   "metadata": {},
   "source": [
    "### All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e17da8a-c733-44ff-8b1d-15149d7e663d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features =[\n",
    " \"mean_time_idx\" ,\n",
    " \"mean_relative_time_idx\" ,\n",
    " \"mean_wrist_x\" ,\n",
    " \"mean_wrist_y\" ,\n",
    " \"mean_wrist_z\" ,\n",
    " \"mean_tendril_mean_x\" ,\n",
    " \"mean_tendril_mean_y\" ,\n",
    " \"mean_tendril_mean_z\" ,\n",
    " \"mean_tendril_std_x\" ,\n",
    " \"mean_tendril_std_y\" ,\n",
    " \"mean_tendril_std_z\" ,\n",
    " \"mean_wrist\" ,\n",
    " \"mean_tendril\" ,\n",
    " \"mean_d_wrist_x\" ,\n",
    " \"mean_d_wrist_y\" ,\n",
    " \"mean_d_wrist_z\" ,\n",
    " \"mean_d_tendril_mean_x\" ,\n",
    " \"mean_d_tendril_mean_y\" ,\n",
    " \"mean_d_tendril_mean_z\" ,\n",
    " \"mean_d_tendril_std_x\" ,\n",
    " \"mean_d_tendril_std_y\" ,\n",
    " \"mean_d_tendril_std_z\" ,\n",
    " \"mean_relative_time_window\",\n",
    " \"std_time_idx\" ,\n",
    " \"std_relative_time_idx\" ,\n",
    " \"std_wrist_x\" ,\n",
    " \"std_wrist_y\" ,\n",
    " \"std_wrist_z\" ,\n",
    " \"std_tendril_mean_x\" ,\n",
    " \"std_tendril_mean_y\" ,\n",
    " \"std_tendril_mean_z\" ,\n",
    " \"std_tendril_std_x\" ,\n",
    " \"std_tendril_std_y\" ,\n",
    " \"std_tendril_std_z\" ,\n",
    " \"std_wrist\" ,\n",
    " \"std_tendril\" ,\n",
    " \"std_d_wrist_x\" ,\n",
    " \"std_d_wrist_y\" ,\n",
    " \"std_d_wrist_z\" ,\n",
    " \"std_d_tendril_mean_x\" ,\n",
    " \"std_d_tendril_mean_y\" ,\n",
    " \"std_d_tendril_mean_z\" ,\n",
    " \"std_d_tendril_std_x\" ,\n",
    " \"std_d_tendril_std_y\" ,\n",
    " \"std_d_tendril_std_z\" ,\n",
    " \"std_relative_time_window\" ,\n",
    "            ]\n",
    "\n",
    "accRF,featRF    = analyse(extracted_features,features,RandomForestClassifier())\n",
    "accLR,featLR    = analyse(extracted_features,features,LogisticRegression())\n",
    "accSVC,featSVC  = analyse(extracted_features,features,SVC())\n",
    "\n",
    "plot_acc(accRF,accLR,accSVC)\n",
    "\n",
    "plot_fi(featRF,featLR,featSVC,features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
