{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf5993-b5e9-44c1-a000-710e3defc01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble        import RandomForestClassifier\n",
    "from sklearn.linear_model        import LogisticRegression\n",
    "from sklearn.svm        import SVC\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold,ShuffleSplit,StratifiedShuffleSplit,GroupShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks #(x, height=None, threshold=None, distance=None, prominence=None, width=None, wlen=None, rel_height=0.5, plateau_size=None)\n",
    "\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4915d199-b458-4509-aaff-3278f0f0ea45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df,x,y,figsize):\n",
    "    plt.figure(figsize=figsize)\n",
    "    for plant_num in np.unique(df.plant_num):\n",
    "        mask = df.plant_num == plant_num\n",
    "        masked_df = df[mask]\n",
    "        if np.unique(masked_df.stimulus)=='thin3d':\n",
    "            plt.plot(masked_df[x]-masked_df[x].iloc[0],masked_df[y]-masked_df[y].iloc[0],c='coral',label='thin3d')\n",
    "        elif np.unique(masked_df.stimulus)=='no':\n",
    "            plt.plot(masked_df[x]-masked_df[x].iloc[0],masked_df[y]-masked_df[y].iloc[0],c='royalblue',label='no')\n",
    "\n",
    "    plt.xlabel(x);plt.ylabel(y)\n",
    "    plt.grid()\n",
    "    #plt.legend()\n",
    "\n",
    "\n",
    "def make_dataset(string):\n",
    "\n",
    "    data = {}\n",
    "    plant_parts =  np.sort(glob.glob(string))\n",
    "\n",
    "    print(\"n. files: {:}\".format(len(plant_parts)))\n",
    "\n",
    "    for single_plant_parts in plant_parts:\n",
    "\n",
    "        folder,data_type,body_part,stimulus,experiment = single_plant_parts.split('/')\n",
    "\n",
    "        plant,stimulus,bodypart      = experiment[:-4].split('_')\n",
    "\n",
    "        if plant not in data.keys():\n",
    "            data[plant] = {'wrist':None,'tendril':[],'stimulus':stimulus,'plant':plant}\n",
    "\n",
    "        print('\\r\\r\\r',plant,stimulus,bodypart,end='')\n",
    "\n",
    "        if 'wrist' in bodypart :\n",
    "\n",
    "            df = pd.read_csv(single_plant_parts)\n",
    "            data[plant]['wrist'] = df\n",
    "            \n",
    "        elif 'tendril' in bodypart :\n",
    "            df = pd.read_csv(single_plant_parts)\n",
    "            data[plant]['tendril'].append(df)\n",
    "\n",
    "        else:\n",
    "            print('bodypart error')\n",
    "\n",
    "    # for each plant\n",
    "    for plant in data.keys():\n",
    "        \n",
    "       \n",
    "        tendril_x = pd.concat(data[plant]['tendril'],axis=1)['col_x']\n",
    "        tendril_y = pd.concat(data[plant]['tendril'],axis=1)['col_y']\n",
    "        tendril_z = pd.concat(data[plant]['tendril'],axis=1)['col_z']\n",
    "\n",
    "   \n",
    "        if type(data[plant]['wrist']) != type(None):\n",
    "\n",
    "           \n",
    "            data[plant]['all_bodyparts'] = {\n",
    "                'time_idx':data[plant]['wrist'].index,\n",
    "                'relative_time_idx':data[plant]['wrist'].index/data[plant]['wrist'].index.max(),\n",
    "                'wrist_x':data[plant]['wrist']['col_x']-data[plant]['wrist']['col_x'][0],\n",
    "                'wrist_y':data[plant]['wrist']['col_y']-data[plant]['wrist']['col_y'][0],\n",
    "                'wrist_z':data[plant]['wrist']['col_z']-data[plant]['wrist']['col_z'][0],\n",
    "                'tendril_mean_x' : tendril_x.mean(axis=1)-data[plant]['wrist']['col_x'],\n",
    "                'tendril_mean_y' : tendril_y.mean(axis=1)-data[plant]['wrist']['col_y'],\n",
    "                'tendril_mean_z' : tendril_z.mean(axis=1)-data[plant]['wrist']['col_z'],\n",
    "                'tendril_std_x' : tendril_x.std(axis=1),\n",
    "                'tendril_std_y' : tendril_y.std(axis=1),\n",
    "                'tendril_std_z' : tendril_z.std(axis=1),\n",
    "                'stimulus' : data[plant]['stimulus'],\n",
    "                'plant_num' : data[plant]['plant']\n",
    "            }\n",
    "            \n",
    "    df = pd.DataFrame([])\n",
    "    for plant in data.keys():\n",
    "        if type(data[plant]['wrist']) != type(None) :\n",
    "\n",
    "            aux = pd.DataFrame(data[plant]['all_bodyparts'])\n",
    "\n",
    "            aux['wrist'] = (aux[['wrist_x','wrist_y','wrist_z']]**2).sum(axis=1)**1/2\n",
    "\n",
    "            aux['tendril'] = (aux[['tendril_mean_x','tendril_mean_y','tendril_mean_z']]**2).sum(axis=1)**1/2\n",
    "\n",
    "            aux['d_wrist_x'] = aux['wrist_x'].diff()\n",
    "            aux['d_wrist_y'] = aux['wrist_y'].diff()\n",
    "            aux['d_wrist_z'] = aux['wrist_z'].diff()\n",
    "\n",
    "            aux['d_tendril_mean_x'] = aux['tendril_mean_x'].diff()\n",
    "            aux['d_tendril_mean_y'] = aux['tendril_mean_y'].diff()\n",
    "            aux['d_tendril_mean_z'] = aux['tendril_mean_z'].diff()\n",
    "\n",
    "            aux['d_tendril_std_x'] = aux['tendril_std_x'].diff()\n",
    "            aux['d_tendril_std_y'] = aux['tendril_std_y'].diff()\n",
    "            aux['d_tendril_std_z'] = aux['tendril_std_z'].diff()\n",
    "\n",
    "            df = df.append(aux)\n",
    "\n",
    "    _,inverse = np.unique(df['plant_num'],return_inverse=True)\n",
    "    df['plant_idx'] = inverse\n",
    "\n",
    "    df['stimulus_idx'] = (df['stimulus'] != 'no').astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f31567e-1e93-485b-8de5-473ed9ed20ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 50\n",
    "\n",
    "def round_to_multiple(number, multiple):\n",
    "    return multiple * round(number / multiple)\n",
    "\n",
    "string = 'Plant_dataset/coordinates/**/**/*.csv'\n",
    "df     = make_dataset(string)\n",
    "df['time_window'] = round_to_multiple(df['time_idx'],window_size)\n",
    "df['relative_time_window']  = df['relative_time_idx'].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b272ad1b-5e18-4e4c-9813-51d01776e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = df.groupby(['plant_num','stimulus'])['time_idx'].max()\n",
    "aux.groupby('stimulus').hist(density=True,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c454f3bf-c7f5-449c-b462-1553e36fc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_cut    = 1505\n",
    "df = df[df['time_idx']<time_cut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730570c-a257-4433-86ef-1595ad78ac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['circumnutation'] = -999\n",
    "\n",
    "x = 'tendril_mean_x'\n",
    "#cut = np.array([(1/180)*1/32,(1/180)*1/16])\n",
    "cut = np.array([(1/180)*1/48,(1/180)*1/16])\n",
    "\n",
    "for plant in df['plant_num'].unique():\n",
    "\n",
    "    mask = df['plant_num']==plant\n",
    "\n",
    "    X,y              = df[mask]['time_idx'].values.reshape(-1, 1),df[mask][x].values\n",
    "\n",
    "    scaler = StandardScaler().fit(df[x].values.reshape(-1, 1))\n",
    "    y       = scaler.transform(y.reshape(-1, 1)).flatten() #[:time_cut]\n",
    "\n",
    "    sos      = signal.butter(4, cut, 'bandpass', analog=False, output='sos',fs=1/180)\n",
    "    filtered = signal.sosfiltfilt(sos, y)\n",
    "    peaks, _ = find_peaks(filtered, height=None,distance=10)\n",
    "    n_max    = y.shape[0]\n",
    "    how_many = np.hstack([peaks[0],np.diff(peaks),n_max-peaks[-1]])\n",
    "    circumnutation = np.repeat(np.arange(how_many.shape[0]),how_many)\n",
    "\n",
    "    df.loc[mask,'circumnutation'] = circumnutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d3e68-ca55-49c8-845b-8658bc22dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = pd.concat([df.groupby(['plant_num','plant_idx','stimulus','stimulus_idx','circumnutation']).mean(),df.groupby(['plant_num','plant_idx','stimulus','stimulus_idx','circumnutation']).std()],axis=1,keys=['mean','std']).reset_index(level=[0,1,2,3,4])\n",
    "extracted_features.columns = ['_'.join(col) for col in extracted_features.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c45c98-c997-4839-9762-2eaf7386ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = ['mean_tendril_std_x' ,'mean_tendril_std_y','mean_tendril_std_z']\n",
    "import seaborn as sns\n",
    "sns.pairplot(data=extracted_features[v+['stimulus_idx_']],hue='stimulus_idx_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93b5300-b578-4b88-809b-6436f9966ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y =  'mean_tendril_std_x' ,'mean_tendril_std_y'\n",
    "\n",
    "def plot(extracted_features,x,y):\n",
    "    fig,(ax1,ax2)=plt.subplots(1,2,figsize=[10,5])\n",
    "    ax1.scatter(extracted_features[x],extracted_features[y],c=extracted_features.stimulus_=='no')\n",
    "\n",
    "    ax2.scatter(extracted_features[x],extracted_features[y],c=extracted_features['plant_idx_'],cmap='Set2')\n",
    "\n",
    "plot(extracted_features,'mean_tendril_std_x' ,'mean_tendril_std_y')\n",
    "plot(extracted_features,'std_wrist_x' ,'std_wrist_y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a295424e-477b-4af1-8226-895159aed939",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y =  'mean_tendril_std_x' ,'mean_tendril_std_y'\n",
    "plt.scatter(extracted_features[x],extracted_features[y],c=extracted_features['plant_idx_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f8c52e-3ebb-447d-9066-2aebbe720707",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse(extracted_features,features,model):#,get_feature_importance=False):\n",
    "\n",
    "    X_not_norm = extracted_features[features]\n",
    "    y          = extracted_features[('stimulus_')].values\n",
    "    g          = extracted_features[('plant_num_')].values\n",
    "\n",
    "    scaler          = StandardScaler().fit(X_not_norm)\n",
    "    X               = scaler.transform(X_not_norm)\n",
    "\n",
    "    gss = GroupShuffleSplit(n_splits=25, test_size=.25, random_state=0)\n",
    "\n",
    "    acc                 = []\n",
    "    feature_importances = []\n",
    "    i = 0\n",
    "    for train_index, test_index in gss.split(X,y,g):\n",
    "        print('\\r',i,type(model).__name__,'                         ',end='')\n",
    "        i+=1\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        #if get_feature_importance :\n",
    "\n",
    "        X_val, y_val = X_test,y_test\n",
    "        r = permutation_importance(model, X_val, y_val,\n",
    "                                    n_repeats=30,\n",
    "                                    random_state=0)\n",
    "        \n",
    "        #feature_importances.append(model.feature_importances_)\n",
    "        feature_importances.append(r['importances_mean'])\n",
    "\n",
    "        y_test_pred = model.predict(X_test)\n",
    "\n",
    "        acc.append(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "    return acc,feature_importances\n",
    "def plot_acc(accRF,accLR,accSVC):\n",
    "    \n",
    "    acc = [accRF,accLR,accSVC]\n",
    "    fig,axs = plt.subplots(1,1,figsize=[5,5])\n",
    "    axs.boxplot(acc)\n",
    "    axs.set_xticks([1, 2, 3], ['RF', 'LR', 'SVC'])\n",
    "    axs.grid(True)\n",
    "    axs.set_ylabel('acc')\n",
    "    axs.set_ylim([0,1.1])\n",
    "\n",
    "    #fig,axs = plt.subplots(1,2,figsize=[10,5])\n",
    "    #axs[1].bar(features,np.array(feature_importances).mean(axis=0))\n",
    "    #_=plt.xticks(rotation=90)\n",
    "    #axs[1].set_title(window)\n",
    "    #plt.show()\n",
    "\n",
    "def plot_fi(featRF,featLR,featSVC,features):\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    dfRF  = pd.DataFrame({'features':np.repeat(features,25),'feature importance':np.array(featRF).flatten()})\n",
    "    dfRF['model'] = 'RF'\n",
    "\n",
    "    dfLR  = pd.DataFrame({'features':np.repeat(features,25),'feature importance':np.array(featLR).flatten()})\n",
    "    dfLR['model'] = 'LR'\n",
    "\n",
    "    dfSVC = pd.DataFrame({'features':np.repeat(features,25),'feature importance':np.array(featSVC).flatten()})\n",
    "    dfSVC['model'] = 'SVC'\n",
    "\n",
    "    df = pd.concat([dfRF,dfLR,dfSVC])\n",
    "\n",
    "    sns.boxplot(data=df,y='feature importance',hue='features',x='model')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12c33a7-c731-4e7d-a0d9-b22d054eb560",
   "metadata": {},
   "source": [
    "### All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdeb684-be11-436c-abae-b3eab668029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features =[\n",
    " \"mean_time_idx\" ,\n",
    " \"mean_relative_time_idx\" ,\n",
    " \"mean_wrist_x\" ,\n",
    " \"mean_wrist_y\" ,\n",
    " \"mean_wrist_z\" ,\n",
    " \"mean_tendril_mean_x\" ,\n",
    " \"mean_tendril_mean_y\" ,\n",
    " \"mean_tendril_mean_z\" ,\n",
    " \"mean_tendril_std_x\" ,\n",
    " \"mean_tendril_std_y\" ,\n",
    " \"mean_tendril_std_z\" ,\n",
    " \"mean_wrist\" ,\n",
    " \"mean_tendril\" ,\n",
    " \"mean_d_wrist_x\" ,\n",
    " \"mean_d_wrist_y\" ,\n",
    " \"mean_d_wrist_z\" ,\n",
    " \"mean_d_tendril_mean_x\" ,\n",
    " \"mean_d_tendril_mean_y\" ,\n",
    " \"mean_d_tendril_mean_z\" ,\n",
    " \"mean_d_tendril_std_x\" ,\n",
    " \"mean_d_tendril_std_y\" ,\n",
    " \"mean_d_tendril_std_z\" ,\n",
    " \"mean_relative_time_window\",\n",
    " \"std_time_idx\" ,\n",
    " \"std_relative_time_idx\" ,\n",
    " \"std_wrist_x\" ,\n",
    " \"std_wrist_y\" ,\n",
    " \"std_wrist_z\" ,\n",
    " \"std_tendril_mean_x\" ,\n",
    " \"std_tendril_mean_y\" ,\n",
    " \"std_tendril_mean_z\" ,\n",
    " \"std_tendril_std_x\" ,\n",
    " \"std_tendril_std_y\" ,\n",
    " \"std_tendril_std_z\" ,\n",
    " \"std_wrist\" ,\n",
    " \"std_tendril\" ,\n",
    " \"std_d_wrist_x\" ,\n",
    " \"std_d_wrist_y\" ,\n",
    " \"std_d_wrist_z\" ,\n",
    " \"std_d_tendril_mean_x\" ,\n",
    " \"std_d_tendril_mean_y\" ,\n",
    " \"std_d_tendril_mean_z\" ,\n",
    " \"std_d_tendril_std_x\" ,\n",
    " \"std_d_tendril_std_y\" ,\n",
    " \"std_d_tendril_std_z\" ,\n",
    " \"std_relative_time_window\" ,\n",
    "            ]\n",
    "\n",
    "accRF,featRF    = analyse(extracted_features,features,RandomForestClassifier())\n",
    "accLR,featLR    = analyse(extracted_features,features,LogisticRegression())\n",
    "accSVC,featSVC  = analyse(extracted_features,features,SVC())\n",
    "\n",
    "plot_acc(accRF,accLR,accSVC)\n",
    "\n",
    "plot_fi(featRF,featLR,featSVC,features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
